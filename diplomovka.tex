\documentclass[12pt, a4paper]{article}

% encoding
\usepackage[utf8]{inputenc}

% graphics packages
\usepackage{graphicx}
\graphicspath{ {images/} }

% misc packages
\usepackage{array}

% special symbols
\usepackage{gensymb}
\usepackage{eurosym}

% pdf packages
\usepackage{pdfpages}

% custom figure counting
\usepackage{chngcntr}
\counterwithin{figure}{section}

% citations
\usepackage{csquotes}

% geometry packages
\usepackage{tkz-euclide}
\usetkzobj{angles}
\usetikzlibrary{calc, through, intersections}

% document settings
\usepackage{times}
\usepackage[top=2.5cm, bottom=2.5cm, left=3.5cm, right=2cm]{geometry}
\usepackage[font={small,it}]{caption}

% page numbering position
\usepackage{fancyhdr}
% Turn on the style
\pagestyle{fancy}
% Clear the header and footer
\fancyhead{}
\fancyfoot{}
% remove the line
\renewcommand{\headrulewidth}{0pt}
% Set the right side of the footer to be the page number
\fancyfoot[R]{\thepage}

% line spacing lists
\usepackage{enumitem}
\setlist{nosep}

% hyperlinks in table of contents
\usepackage[hyphens]{url}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

% biblopgraphy
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
 
\usepackage[backend=biber]{biblatex}
\addbibresource{bibliography.bib}

\makeatletter
\g@addto@macro{\UrlBreaks}{\UrlOrds}
\makeatother

%angles in degrees
\def\nswe#1#2#3{#1\,$#2^\circ\,#3'$}

% under the line notes numbering per page
\usepackage{perpage} %the perpage package
\MakePerPage{footnote} %the perpage package command

% paragraphs settings
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}
\linespread{1.5}

% sections settings
\usepackage{sectsty}
\sectionfont{\fontsize{16pt}{1em}\selectfont}
\subsectionfont{\fontsize{14pt}{1em}\selectfont}
\subsubsectionfont{\fontsize{12pt}{1em}\selectfont}

% page break before \section
\usepackage{titlesec}
\newcommand{\sectionbreak}{\clearpage}

% horizontal line below \section
\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}[{\titlerule[0.8pt]}]

% line spacing in table of contents / list of figures
\usepackage{tocloft}
\setlength\cftparskip{2pt}

% better commands
\usepackage{xparse}

% image figure
\usepackage{float}
\NewDocumentCommand\imgfigure{O{h}O{0pt}mm}
{
	\begin{figure}[#1]
		\centering\includegraphics[width=\textwidth - #2]{#3}
		\caption{#4\label{fig:#3}}
	\end{figure}
}

% geometry figure
\usepackage{environ}
\NewEnviron{geofigure}[3][1]
{
	\begin{figure}[H]
		\centering
		
		\begin{tikzpicture}[scale=#1, every node/.style={scale=#1}]
			\BODY
		\end{tikzpicture}
		
		\caption{#3\label{fig:#2}}
	\end{figure}
}

% reference to figure
\newcommand{\reffigure}[1]
{
	figure~\ref{fig:#1}~(page~\pageref{fig:#1})%
}

% same as reference to figure (\reffigure) but with capitalized first letter
\newcommand{\Reffigure}[1]
{
	Figure~\ref{fig:#1}~(page~\pageref{fig:#1})%
}

% section without numbering but with entry in table of contents
\newcommand{\specialsection}[1]
{
	\section*{#1}
	\addcontentsline{toc}{section}{\protect\numberline{}#1}
}

% definitions
\usepackage{enumitem}
\newenvironment{definitions}
{\begin{description}[style=nextline]}
{\end{description}}

% references

\newenvironment{references}
{
	\newcommand{\entryref}[1]
	{
		\label{ref:##1}
	}
	
	\newcommand{\entrypaper}[5]
	{
		\item \entryref{##1} ##2, ##3, \textit{##4} (##5)
	}
	\newcommand{\entrylink}[6]
	{
		\item \entryref{##1} ##2, ##3, \textit{##4}, URL (accessed \textit{##6}): \sloppy\url{##5} 
	}
	\newcommand{\entrymanual}[4]
	{
		\item \entryref{##1} \textit{##2}, URL (accessed \textit{##4}): \sloppy\url{##3} 
	}

	\begin{enumerate}
}
{
	\end{enumerate}
}

\newcommand{\rref}[2]
{
	(\textsc{#1, #2})%
}

\newcommand{\simplerref}[1]
{
	(\textsc{#1})
}

% code formatting
\newcommand{\code}[1]
{
	\texttt{#1}
}

% todo for notes
\newcommand{\todo}[1]
{
	\textcolor{red}{#1}
}

% figures section name
\renewcommand\listfigurename{Figures}

\begin{document}

\pagenumbering{gobble}

% table of contents
%\singlespacing
\tableofcontents

% list of figures
%\newpage
%\listoffigures

\newpage

\pagenumbering{arabic}
\setcounter{page}{4}

\specialsection{Dictionary Acronyms and Abbreviations}

\begin{definitions}
	\item[Mediated Reality] Computer-mediated reality - A summary term for adding, removing or otherwise altering one’s perception of reality with the help of computer systems such as portable computers or hand-held devices. Mediated reality serves as a wide superset of technologies like virtual reality, augmented reality or mixed reality.
	\item[MR~~~] Mixed reality - The term can be used to any system, where real and virtual objects blend to any degree, creating new environments and visualizations. The ratio in which real and virtual objects are mixed can range from almost completely real to exclusively virtual environments. Virtual and augmented realities are subsets of mixed reality.
	\item[VR~~~] Virtual Reality - A summary term for technologies and devices employing these technologies, capable of stimulating human senses in a way that creates an effect of the user experiencing a different environment instead of the real one. Generally, the most common idea of a VR device is a special headset with twin stereoscopic displays and lenses through which a user can see and interact with an artificial three-dimensional simulation.
	\item[AR~~~] Augmented Reality - A family of technologies closely related to virtual reality with the difference that instead of replacing the perception completely, augmented reality “adds” digital objects and elements into the direct or indirect view of the real world. The effect is achieved by analysing the surroundings and drawing the digital object over the real world image to create an illusion of the object actually being present. A similar, yet less known technology called diminished reality aims to remove real world objects from the screen to create an illusion of them not existing.
	\item[HMD~] Head Mounted Display - A device intended to be attached on user’s head able to display data on special displays positioned close to the user’s eyes. Depending on the type of the display and intended use, the real world image can be directly or indirectly visible to various degree or blocked out completely. One of the most important parameters of a HMD is their field of view - the parameter defining the area of human sight that the display is capable of covering with virtual objects. Also commonly regarded as a headset.
	\item[FPS~] Frames per Second - A term used for a metric defining the amount of images that are displayed on a screen during a one second interval. Higher FPS means new images are displayed on the screen more often increasing the fluidity of the image.
	\item[FOV~] Field of View - Defines the extent of the observable (both virtual and real) world that is seen or displayed at any given moment. It can be measured horizontally, vertically, or diagonally, and it defines the angular distance between the corners of visible image.
	\item[IMU~] Inertial Measurement Unit - A hardware sensor, possibly consisting of other sensors - accelerometers, magnetometers, gyroscopes etc. The purpose of the unit is to measure positional and rotational changes with maximum possible precision. An IMU plays a crucial role in most today’s augmented and virtual reality devices.
	\item[SLAM~] Simultaneous Localization and Mapping - It is a computational problem in which an unknown area is mapped by an agent while the agent is keeping track of its position within the area at the same time. Several algorithms exist today that are able to approximate SLAM calculations.

\end{definitions}

\section{Introduction}

The problematics of virtual (VR) and augmented reality (AR) has been employing technology enthusiasts from scientifical and science-fiction circles for decades, yet the technological limitations and high price generally prevented widespread commercial popularisation or restricted real world use to highly specialized areas of application. Only in recent years technologies with sufficient parameters started surfacing on the market that would offer high enough quality reproduction at a reasonable price. To fill the rapidly growing market for AR/VR has became an important goal for numerous technological giants. We are therefore witnessing new breakthroughs in the area with unparalleled frequency. While often still in development or demonstrator phases, the prototypes make their way to startups and development companies who explore their possibilities and come up with real-life problems that could benefit from augmented or virtual reality. Thanks to that, we can already experience a virtual roller coaster ride, take a walk on the ocean floor, simulate and practice in a control room of a cargo ship that has not yet been built, lay out virtual furniture in your apartment before buying it, or pilot a fast car or an airplane directly from the cockpit.

Despite the intense development in the area and unquestionable success of some AR/VR systems, numerous challenges and untackled problems remain. In order to offer high enough quality virtual reality experience, the devices require displays with extreme resolution and sufficient screen refresh rate while being able to detect headset and controller rotation and position changes precisely and swiftly enough to incorporate them into the image displayed back to the user. The result should be an user perceiving different surroundings than those he or she is physically present in. For augmented reality, the requirements are even higher - virtual objects have to be perfectly anchored to their real surroundings in various (often adverse) conditions. Overcoming these challenges often calls for custom-tailored solutions to emerge (dedicated visualization hardware, specialized sensors) but there are still many applications where AR/VR is not mature enough. 

Furthermore but also thanks to this, it is often not necessary to employ AR/VR in areas where a standard computer screen provides a more intuitive / cheaper / better solution. Finally, there are still unresolved difficulties regarding user health, especially in regard to virtual reality headsets - motion sickness, disorientation, headaches, eye fatigue etc (Not taking into account injuries or damage caused by immersing into the virtual experience too much and tripping or hitting objects in the designated VR area).

The technologies of augmented and virtual reality will have to face a long and uncertain journey before becoming an everyday part of our lives or disappearing altogether should insolvable challenges arise in the future. It is therefore exciting and favourable to be able to experience and examine the capabilities of today’s technologies and attempt to find where their boundaries are. The main questions awaiting answers are what is the current state of the AR/VR market, that level of precision do the devices offer in various price categories and what kind of problems, if any at all, are there to be solved by them.

\section{The Historical Development of AR / VR Devices}

The advent of devices and technologies, commonly known and classified as virtual and augmented reality today was preceded by a number of inventions and artistic renditions that served as predictions of future technologies and developments. From a broader point of view on AR/VR, there is a number of applications that can also meet a simplified definition of artificially altering our experience of reality. If we redefine the broader term as some kind of artificial way intended to stimulate the senses in a different than usual way, altering or enhancing the perception of reality, we might come to a conclusion that one of the simplest inventions to meet these criteria might be a simple drawing or a painting. The purpose of such picture (or any other non-abstract object for that matter) on it is to provide viewers with an idea of a country like they were present at the actual place the creation was made. One step further is a photography - analog or digital one. It generally has the same purpose of providing a view of a place, person, or an event even on a distant place or at a later time. A 360\degree panoramic photo brings the concept of photography into a more immersive level by capturing the whole area around of the author and letting viewers look around using their mouses or by rotating their smartphones. This results in a feeling of actually being present in the scene, yet the application is not suitable for all situation and has not replaced traditional photographs completely.
 
When looking at the current state of the art technologies, examining The Lab - a set of minigames provided for free as a technological demonstrator for a VR system HTC Vive, one of the games allows users to explore one of 4 locations in complete virtual reality and move around them to a limited extent. The locations are made in photorealistic quality and exhibit real world locations. One of which exhibits Vesper Peak, a peak in North Cascades in Washington (\nswe{48}{00}{47}N \nswe{121}{31}{04}W). The realism and immersion is so high that standing on the edge of a cliff accessible in the virtual location can induce altitude sickness and pushing the person exploring the virtual scene down can result in a panic attack.

\imgfigure{vesper_peak_vive_real}{A comparison of a real photo from Vesper Peak and its representation in HTC Vive}

\subsection{The Pioneers of VR Concepts}

Historically, the first attempts at deliberately immersing the viewer in an artistic scene can be seen on 19th century panoramic mural paintings. The whole field of vision was filled by the picture seemingly placing spectators into a different environment.

Another key invention considered ordinary today is understanding of how human eyes work and process what they see. Each eye is able to observe single 2D sight and the process of creating a 3D model of the person’s surroundings and sensing depth based on sight is handled by the brain. The person behind this realization is English scientist and inventor Charles Wheatstone - author of stereoscope. The device uses a pair of lenses to display a stereoscopic image pair to the user creating a three-dimensional illusion. The principle of a separate screen for each eye is a cornerstone of today’s VR and AR devices.

As the world advanced, the technological progress in many areas allowed for a wider area of utilization and practical applications became more frequent. One of the first industries to start benefiting from virtual experience creating a simulation of reality was aeronautics and military. Edwin Albert Link, an American aviation and underwater archaeology pioneer created a device known as “Blue Box” or “Link Trainer” that is today considered to be the first flight simulator ever created. The electromechanical device was used in basic pilot training to promote faster, cheaper, and safer ways to obtain skillful pilots. The device could mimic responses to flight controls and and gave an accurate reading on cockpit instruments, helping the trainees learn utilize them when piloting. During WW2, more than 500,000 American  pilots had a part of their training done on a Blue Box.

Along with technological development, we can also look back on historical cultural predictions in the form of science-fiction literature and movies that undisputedly helped shape the world we live in today. It was already in 19th century Jules Verne predicted inventions like submarines, television newscasts, videoconferences or human landing on the Moon. A work of fiction strikingly similar to today’s augmented and virtual reality headsets came from the pen of  Stanley G. Weinbaum in 1935. The short story - Pigmalion’s Spectacles elaborates on an idea of a pair of goggles allowing their user to experience a fictional world via holographics, sound, smell, taste, and touch. The googles also allow the user to interact with the world - it is possible to talk to fictional characters named shadows with them being able to reply back. In 1901, American Author L. Frank Baum released The Master Key - a novel about a young boy who is given a set of magical artifacts from a supernatural “Demon of Electricity”. Amongst these is a set of spectacles that place a letter on the forehead of anyone the wearer sees depending on their personality and traits.

\subsection{1960s - The First Virtual and Augmented Reality Devices Appear}

Since the technological concepts have already been defined and the age of microchips steadily seeped into everyday life, the first practical attempts started emerging, along with more concepts being defined. During this period, up until around 1990, most if not all VR concepts have been lain out and the only technological challenge has been to increase the image replication quality. Augmented Reality is generally more complex, having to juxtapose virtual reality with area learning and real objects detection.

In 1962, Morton Heilig, a pioneer in VR technology and a cinematographer patented his multi-sensory, immersive cinematic machine called Sensorama, built 5 years earlier. The prototype machine served as a vision of the future of cinema, where multiple senses would be stimulated and the viewers would be engaged further. The arcade-style theatre cabinet device contained stereo speakers, a stereoscopic video display, fans, smell generators and a vibrating chair. The short films that could be played on the device were named Motorcycle, Dune Buggy, Belly Dancer, Helicopter, A Date with Sabina and I’m a Coca Cola Bottle.

Another invention from Heilig, the Telesphere Mask, patented in 1960, is considered the first ever HMD, despite not supporting any interactivity or head position or movement tracking. The device offered a pair of stereoscopic widescreen displays as well as a pair of stereo speakers. Another head-mounted display, this time with simple head tracking, called Headsight, was developed a year later. Its authors, Comeau \& Bryan from Philco Corporation used a magnetic system to determine rotation of the headset and a single CRT element for displaying. The intended purpose of the gadget was to provide remote sight in dangerous situations using a closed circuit camera.

In 1965, Ivan Sutherland, an American computer specialist and internet pioneer, widely regarded as the “father of computer graphics”, laid down a document that would later become a core blueprint for concepts encompassing virtual and augmented reality today. Named “The Ultimate Display”, the paper investigates the ways in which computer data could be displayed to the users as well as what approaches are there to input data into computers. Ultimately, he describes systems that would monitor the movement of each human muscle or eye focus and generate and maintain entire simulated virtual worlds as realistic and tactile as reality.

\begin{displayquote}
\textit{“The ultimate display would, of course, be a room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal. With appropriate programming such a display could literally be the Wonderland into which Alice walked.“}
\end{displayquote}
\begin{flushright}
- Ivan Sutherland
\end{flushright}

In 1968, together with his student Bob Sproull, he created the first ever augmented and virtual reality head-mounted display system called The Sword of Damocles. Its technological primacy lied in the fact that it used a computer generated image for the display instead of using cameras like former systems, as well as in the fact that the image shown to the user depended on where he or she gazed - calculating the direction where the user is headed towards is called head tracking. The Sword of Damocles name originated from the fact that the headset was suspended from the ceiling on a mechanical arm and securely fastened to user’s head. The components of the system were not fully interconnected and the whole contraption’s main purpose was to serve as a prototype for “the ultimate display” research. The display showed primitive wireframes (limited by the computing power of general-purpose computers of the time) with the unit being partially see-through. Thanks to that it is today considered to be one of the first augmented reality precursors.

Another of the milestones towards today’s AR / VR as we know them was the work of Myron W. Krueger, an American computer artist accountable for many early interactive works and considered one of the first virtual and augmented reality researchers. He is behind a series of gradually improved interactive experiences called GLOWFLOW, METAPLAY, and PSYCHIC SPACE which ultimately progressed into a technology called VIDEOPLACE. The idea of the technology was to immerse users in a virtual experience without the need for any goggles, gloves or other wearable hardware. Instead, a set of projectors, cameras, on-screen projections and specialized hardware surrounded the users and responded to their movements and actions. To interact with others, a silhouette was created from the person and projected on the wall as an avatar where it could interact with other users also represented as silhouettes. Kreuger summarised his experience in the area of interactive artificial worlds along with his future visions in his 1983 book Artificial Reality and its revised version Artificial Reality 2 in 1991.

Back in 1978 at MIT, a revolutionary hypermedia system was developed by a team led by Andrew Lippman with fundings from ARPA (Advanced Research Projects Agency). Called Aspen Movie Map, it was the first predecessor of systems like today’s Google Street View. The original motivation behind the system was enabling soldiers to familiarize with unknown environments quickly and was inspired by Israeli commandos’ Operation Entebble in 1976, where the soldiers built a crude replica of an airport terminal to train before commencing the real operation. Aspen Movie Map was a system providing virtual tours of the city of Aspen, Colorado. The researchers used a car with 4 orthogonal cameras to create a view of the city from a travelling car every 3 metres. The interactive system was touchscreen controlled and it allowed the user to create a travelling path in a city-map view and then enjoy a surrogate car ride among the specified path. Three modes were available: early autumn, winter, and computer generated wireframe and could be switched at any time.

In 1980, Canadian researcher and inventor Steve Mann created one of the first wearable computers. The system combined a computer vision system with graphical overlays on photographically mediated reality and could basically allow the human eye to serve both as a camera and a monitor. The mechanism was placed directly in front of a human eye and it records the view using a lens, processes it and displays it back to the eye using the same lens, possibly being augmented with digital data. Called “Digital Eye Glass”, “Eye Glass” or “Glass Eye” by its inventor, the heavy and cumbersome device covering the whole head ultimately evolved into EyeTap, which, while using the same principle looks like a fairly ordinary eyeglass frame. One of the main advantages of the design is the image perceived by the camera is exactly the same as the one seen by the eye so mapping digital objects using computer vision and image processing has great potential in terms of augmented reality (the original image and the real surroundings are still visible to the user). EyeTap, in terms of its appearance and capabilities, can be considered to be the 10 years older brother of Google Glass. Mann predicts that in the near future most people will use wearable headsets with camera capabilities enabling us to record every moment of our lives (This is a questionable claim for the near future considering Google Glass did not hit mainstream success).

\subsection{1980s - Virtual Reality Comes to Life}

The term \textbf{Virtual Reality} that is generally widespread today was actually popularized by Jaron Lanier, an American computer scientist, visual artist, and a music composer through the second half of 1980s. His company, VPL Research, founded in 1984, was among the first companies to develop and sell virtual reality devices commercially. Lanier originally worked for Atari Inc in their dedicated virtual reality lab, but after the North American video game crash of 1983 the lab got closed down and Lanier along with his colleagues became unemployed. VPL Research brought several VR devices to the market: Data Glove - an input system tracking hand movements and orientation, EyePhone - a HMD with fresnel lenses and head movement tracking capabilities, Data Suit - a full-body outfit capable of tracking and measuring movement of trunk and limbs. Despite initial success the company filed for bankruptcy in 1990 and the remaining patents were bought by Sun Microsystems in 1999.

Long before virtual and augmented reality hardware even started becoming widely accessible for household ownership, some degree of public exposure was provided when Virtuality Group (originally named W Industries), a United Kingdom based company started offering a range of arcade games and machines. Players enjoying this experience would use 3D head mounted displays and various joysticks, steering wheels or aircraft yokes (depending on the system and game) for controls. Some systems supported multiplayer by having several stations networked together. Their headset tracking real-time response was only 50 ms (today, 16 ms is considered to be the limit). Two device types were available depending of how the player was positioned: sitting and standing units. The display resolution was 276x372 pixels for each eye and apart from the stereoscopic LCD displays, each headset contained 4 speakers and a microphone. A magnetic system was used to detect head and controller movements and allowed the system to respond accordingly. Despite being initially a huge success and stating its aim to be far beyond simple entertainment systems, Virtuality Group failed to deliver convincing advancements and filed for bankruptcy in 1997.

One of the milestones undoubtedly interconnected with the rapid rise of virtual reality in the early nineties was The Lawnmower Man directed by Brett Leonard in 1992. In the sci-fi action horror movie, a scientist uses a mix of intelligence enhancing drugs and virtual reality on a simple-minded gardener to improve his cognitive abilities. After some time the experiment spirals out of control as the test subject is able to take control and start pursuing his own goals. The movie was strongly inspired by Jaron Lanier, VPL, and other VR companies of the time. This is easily visible in the fact that many of the props used thorough the movie are actual VPL equipment and the opening credits of the movie predict VR to be in widespread use by 2000 with all possible positives and drawbacks the technology could bring humanity.

Not much longer after arcade machines from Virtuality initially succeeded commercially and marked a new potential market, major home entertainment system manufacturers announced their own virtual reality systems. Sega announced its Sega VR headset in 1993. Coupled with a Sega Genesis or Saturn console, the headset would have twin LCD display and stereophonic speakers. Inertial sensors would allow the headset to respond to head movements. Complications during development and possible problems with headaches and motion sickness prevented the console from ever reaching beyond prototype stages. A similarly grim fate awaited a competitor product, Nintendo’s Virtual Boy. It was supposed to be the first portable console with 3D graphics and was actually commercially released in Japan and North America, but its specifications were nowhere near desirable. The portability of the console was questionable, it was uncomfortable to use, only offered a red and black display and most of the games did not benefit from being 3D at all. No head movement tracking was supported.

Between 1995 and 2000, the market of AR and VR devices started to fall as the expectations from the technology were displaced by the overwhelming technical limitations of computer electronics of the time. During the nineties, AR and VR was seen as the next technological step in technological development and much energy was invested into making higher precision devices possible. There are two main reasons for the hype dying out as the new millennium approached. The hardware was remotely not powerful enough to enable precision and interaction levels beyond basic graphics thus limiting the potential usages to very specific cases also negatively affecting the market potential. Secondly, the main focus of most companies switched to the internet as it became the most anticipated and promising technology at that time, leaving AR and VR behind for some time. This does, however not mean the development stopped completely - many companies remained operative, often thanks to specific field contracts like military simulation or universities, but the general public stopped being so interested in the technologies until acceptable quality devices become widely available.

Perhaps the most influential movie where virtual reality as a concept played the main role is 1999’s The Matrix by The Wachowski Brothers. In the movie a computer hacker is contacted by a group of rebels to learn that he’s been living his entire life in an extremely realistic computer simulation. There are no HMDs or other kinds of hardware used, the connection into the simulated world can be done directly via a brain interface basically breaking all bonds between user’s body and mind. The movie has both envisioned a possible peak of both virtual reality and computer system user interfaces (by having a brain-computer interface directly on the body eliminating the need for displays and input peripherals) and restarted a debate about the possible consequences of such technologies.

A little less technologically advanced form of virtual reality, very close to Ivan Sutherland’s Ultimate Display appeared in Star Trek: The Next Generation. Nicknamed the Holodeck, the system is capable of simulating matter together with complete interaction and even being possibly harmful to its users. Holodeck itself is a room of considerable proportions within which the virtual phenomena was simulated.

\subsection{2000s - The Development Continues}

After the wild blossom of AR/VR technologies in the nineties and despite the virtual reality hype dying out, a wide range of companies and universities continued pushing the boundaries further and finding new areas where the concepts could be employed. In 1999, Hirokazu Kato released the first version of ARToolKit, an (now) open source library for augmented reality using special trackers - tags / ARTags. The library is still being developed and  remains one of the dozens readily available AR/VR solutions on the market. From 1999 onwards, several augmented reality technologies were tested that overlaid virtual map data over real world video simplifying navigation and awareness. Similar programs gradually emerged for military use. The development was continuous and the technologies slowly creeped into more and more areas - medical, entertainment, navigation, translation etc. The first cubic room, SAS3 or SAS Cube was created in 2001 in France by Z-A Production. This type of a VR system is today widely regarded to as CAVE (cave automatic virtual environment). It usually consists of a cubic room combining a set of projectors on three to six walls and other specialized hardware intended to help viewing (3D glasses) or interacting with the virtual simulation.

In 2007, 29 years after Aspen Movie Map, Google launched Street View, a technology featured in Google Maps and Google Earth that enables panoramic views of city streets for select American cities. The technology has since expanded to contain practically every city in the world letting anyone with internet connection to virtually travel to any destination. Together with online maps and GPS navigation, it is today easily possible to explore a place before physically visiting it, allowing us to check a hotel’s surroundings or road directions before even deciding to travel there.

In 2011, the first prototypes that eventually gave birth to Oculus Rift was made by Palmer Luckey, an American entrepreneur who eventually founded Oculus VR company to enable commercial use of his devices. The project later sparked a Kickstarter campaign and basically started what can be considered the second VR revolution today. Luckey originally developed several prototypes with various parameters, sizes and weights. His first prototype, built into a different headset’s body, only supported rotational tracking, but it incorporated 90\degree field of view, previously unseen on the consumer market. The HMD also inspired Id Software to announce 3D headset support for their Doom 3 release.

The situation was not so bright in the augmented reality sector. The technological difficulties encountered in AR devices are often more complex than those in VR and there are usually tighter constraints regarding the device’s raw computational power. LyteShot, an augmented reality gaming platform by a same-name company, launched in 2012. Using specialized hardware and smartphones with bluetooth connectivity, the devices enable various types of real-life games with digital processing handling things such as scoring, game quests, removing players from the game etc. Today, similar systems are widely used in laser-tag arenas, where players can see their scores and real-time metrics instantaneously. Meta, a Silicon Valley based company, launched a Kickstarter campaign for what would later become one of the first see-through augmented reality glasses - Meta 1 development kit. The company was aiming to provide a means of displaying virtual objects in real world for uses like medical training or engineering. The headset boasts twin displays, accelerometer, gyroscope, compass, and a depth perceiving camera. Field of view is limited to 23\degree per display and the headset weighs 300 grams.

One of the most influential and publically known augmented reality devices was Google’s Google Glass which was announced in 2012 and entered public beta in 2013. The first internal prototype of the device using a head-mounted display weighed over 3 kilograms. The publically available version of the device is lighter than a pair of sunglasses. The computational power is somewhat limited and most of the resource-heavy calculations are done on a smartphone, to which the glass is paired via bluetooth. Hardware-wise, Google Glass has a 720p camera, bone-transmitting audio conductor, a microphone, 640 x 360 LCoS (liquid crystal on silicon) display using a collimating reflector to direct the beams into the wearer’s eye, 1 GiB of RAM, dual-core 1,2Ghz ARM CPU and 12GB of memory available to the user. Interaction with the device was possible via an intuitive touch panel, voice commands or even head movement gestures. Movement was tracked by a 3 axis gyroscope, 3 axis accelerometer and a 3 axis magnetometer (compass). Google announced that Glass would be discontinued in 2015, stating that its development will continue until commercial-readiness is achieved.

Design-wise, Google Glass is meant to work as a supplement to a smartphone, simplifying and extending its use. Taking photos or videos does not require using one’s hands and various notifications such as SMS messages or social media mentions get displayed to the user directly. The short battery life together with high price and scarcity of useful applications would be the main reasons for discontinuing the wearable. Some degree of use was found nevertheless - healthcare, journalism and military all benefitted from the hands-free interface and the portability of the device’s camera. However, both the SDK support and computational power do not provide nearly enough functionality to support more sophisticated AR applications.
https://developers.google.com/glass/distribute/glass-at-work

\subsection{Current Technologies}

One of important breakthroughs in VR display technologies was made in 2013 by Valve Corporation in the field of display persistence. In order to ensure nausea-free and highest-possible quality immersion, the screen must be refreshed as often as possible without any interruptions. Sixty \textbf{frames per second} (fps) is considered the absolute minimum for believable virtual reality experience, although it is believed, refresh rates as high as 1,000 Hz are needed for a perfect experience - something we can not achieve with current technology. The breakthrough, so important for VR was a new type of display with considerably lower persistence rate, which, together with using strobing/black frame periods allowed for lower motion blur effects and sharper display. All subsequent VR headsets employed this type of displays.

Another development that turned out to serve as a basis for two of today’s best VR headsets was Valve’s internal Steam Sight prototype. The technologies for the headset itself (not positional tracking) ended up basically unchanged in production versions of both HTC Vive and its concurrent Oculus Rift HMDs. Value claims to have lent a single Steam Sight piece to Oculus VR before it was acquisited by Facebook in 2014 with Oculus using it as an inspiration while working on Rift.

A device meant to encourage VR awareness and developer interest in the technology, named Google Cardboard was announced on Google I/O conference in 2014. The Cardboard belongs to the lowest price category for VR devices and is meant to be coupled with a smartphone - thanks to that, the cost of a single unit is only around 15\$. It basically consists of a primitive cardboard headset with 2 lenses and a magnetic button used to interact with the device (phone’s internal compass is used to detect interaction). Motion (rotational) detection relies on the phone’s accelerometers and gyroscopes. A great amount of similar HMDs have since been created and are available on the market with Samsung’s GearVR possibly being the best known one.

Apart from Oculus, which gained a massive momentum boost in 2014, when it was acquired by Facebook for over 2 billion dollars and is shipping the consumer version of Rift today, two more virtual reality headsets hold a strong position on the market, Playstation VR by Sony, originally codenamed Project Morpheus, first announced in 2014 and HTC Vive, a cooperation between HTC and Valve. All three headsets support full positional tracking and various kinds of controllers are supported. Rift was released in April 2016, Vive one month later, Playstation VR came out in October 2016.

An interesting technology with considerable AR potential that has recently reached consumer availability is Google’s Tango, previously known as Project Tango. Originally announced in 2014, the AR platform combines computer vision, depth perception, and motion tracking to provide high quality information about the surroundings the device is in. Thanks to the technology, a tango-enabled device is able to create 3D models of rooms and objects, measure distances inside rooms or ad virtual objects into real world. Currently, one Android smartphone supports the technology - Lenovo Phab 2 PRO, with Asus announcing its Tango phone - ZenFone AR in January 2017.

The current state-of-the-art AR technology is currently believed to be Microsoft’s HoloLens. Currently available worldwide as a developer edition and originally introduced in January 2015, its roots can be traced back to 2010, when Kinect - an add-on to Microsoft’s Xbox gaming console, was released. HoloLens is a headworn HMD with twin see-through displays and hi-performance hardware that is capable of placing virtual holograms into the user’s surroundings and track their positions there. There are a number of features that appoint HoloLens the best AR platform currently available with only a few possible drawbacks: price (3000\$), field of view (estimated to be 30\degree~x 17.5\degree for each display), and battery life of 2 to 3 hours. 


As of early 2017, there are hundreds of companies working on AR and VR applications in a wide area of applications both applying the current technologies to real life and extending the possibilities with new technologies. With the arrival of Oculus Rift, HTC Vive, and Playstation VR, more and more customers are engaged into virtual experiences in their homes or trying them out in businesses that rent them. Similarly, the AR market saw considerable public exposure with Niantic’s Pokemon GO mobile game, that was released for Android and iOS in July 2016 and saw massive success. The player’s position in the game world depends on his or her real life position using GPS and once catching a virtual companion in the game, the pokemon would be displayed in the real world using phone’s camera. Google’s continued expansion into the VR market led to Google Daydream, a cardboard-like headset meant to be used with a daydream-ready phone. The headset does have a special controller with gyroscope and trackpad that is arguably more comfortable to use than Samsung’s GearVR that has a gamepad on its right side. In March 2017, Apple Inc’s CEO TIm Cook has announced the company will focus on AR market development in the short future, seemingly confirming the fact that the market is going to see even greater expansion in the upcoming years.

\section{Technical Specifications and Requirements}

Depending on the technology used and the overall design of various systems, a diverse amount of advantages and drawbacks can be identified for every system. This chapter explains the requirements that need to be met in order to offer the highest quality object mapping and experience. 

There are two main objectives to be handled by the AR and VR systems: position and environment detection and displaying virtual objects. The first system is responsible for figuring out the position and alignment of the device, passing these parameters to the engine and renderer, ensuring the image displayed to the user aligns with positional and rotational changes perfectly.

\subsection{Basic Concepts}

\subsubsection{Headset Position Detection}
For the clarity of the explanation, we will consider any device meant to display virtual or augmented experience to be a headset. Basically, there are two types of devices in this category - screens (computer, handheld device) and actual headsets (single eye, full-face HMDs). In order to make the headset appear in virtual space closely tied to reality, all its movements and translations in the real world should closely correspond to changes in the virtual world display. Here, the term \textbf{six degrees of freedom} (6DoF) is most commonly used. The term relates to three possible translation and three rotation axes, specifically translation forward/backward, left/right, up/down and rotation about three perpendicular axes - pitch, yaw and roll. Not all headsets support every axis movement/rotation detection, though they are all necessary for augmented reality applications.

The most trivial to solve are the three rotation axes - a headset with precise accelerometer, gyroscope and magnetoscope can quite successfully approximate its orientation and acceleration (accelerometer data), rotation changes (gyroscope) and current heading (magnetometer or compass). These internal sensors are present in most smartphones today making Google cardboard-based VR easily accessible, though moving one’s head does not get translated into the virtual world. Another drawback of this system is the relativity of heading. Usually, the virtual world will be displayed in the heading the user puts the headset on.

For the position axes, specialized systems need to be utilized - from external sensors detecting headset position to depth cameras and computer vision scanning the device’s surroundings. Generally they vary with the area they can cover, their position, precision and price.

\subsubsection{Displaying Virtual Objects}

In order to render objects in virtual space, a camera has to be specified with a position, orientation and other parameters such as field of view, to know what objects will be displayed in the final image. Most 3D rendering software today works without augmented and virtual reality position detection, only changing the position based on user input from keyboards, mice, joysticks or other devices. The subtle change done by mixed reality systems is relying on position detection systems for this input. For handheld devices such as phones with augmented reality-enabled applications (most often using device cameras) or Google’s Project Tango-enabled phones, the requirements are basically the same as for any other 3D program - some amount of lag, delay, or drift is acceptable, yet undesirable. On the other hand, HMDs need to tie the rendered objects with real-world device orientation perfectly with the lowest-possible delay, making them significantly more performance demanding. There generally need to be two stereographic images instead of one, they require special lens distortion - a counterreaction to physical lens distortion, ensuring wide field of view, and 60 frames per second at all times is the bare minimum to minimize motion sickness. There are several approaches to solve these problems based on the requirements and technologies used.

\subsubsection{Virtual Reality Sickness} 
The main reason for such a gap in the requirements placed on handheld and on-screen mixed reality devices and HMD-based systems lies in the way they affect perception. When external screens are used, users easily recognise that the image on the screens is emulated and despite being closely tied to real world, not replacing reality in any way. With HMDs, especially virtual ones, real world perception is dampened and users have to completely rely on the virtual experience. The human body uses two main mechanisms to orient itself in space: visual orientation and the vestibular system. The first consists of understanding the shape of our surroundings and positioning and moving ourselves accordingly. The latter is a sensory mechanism located in the inner ear, capable of detecting translation and rotation changes\footnote{A test popular amongst children that proves the systems work together is to try standing on one leg while keeping balance with and without one's eyes closed.}. If the stimuli coming from both systems does not match up (eg. movement in the virtual environment while not feeling any inertia) or are of inconsistent quality (lag, latency spikes, high persistence displays, motion blur), sickness and discomfort may appear. There are many potential factors affecting virtual reality sickness and the whole area is not yet fully understood.

For augmented reality headsets, the virtual reality sickness does not pose a problem since real-world perception is still present, but high-performance detection is still desirable to ensure virtual objects do not twitch and are solidly anchored to their real space coordinates.

\subsection{AR / VR Device Classification}

In order to be able to compare the technologies and their capabilities, it is essential to identify which parameters play a crucial role defining the strengths and drawbacks of each platform. The possible ways a device could be utilized depend on factors like price, availability, portability, quality of movement detection, detection area limitations, computational power, support, development tools quality etc.

\begin{definitions}
\item[Price] defines the availability of the product plus a soft constraint on the performance. Currently, the cheapest ways to get to both AR and VR can start at 0 - 50\euro, provided a smartphone, tablet or a computer with a camera are present. A device with a camera can learn to recognise special markers and add a virtual object into the camera screen thanks to one of the numerous AR frameworks available today. In the VR market, a headset is required - Google Cardboard is the cheapest way of converting a smartphone into a simple headset. More expensive smartphone mounts exist up to Samsung GearVR, which retails for about 130\euro and only works with Samsung Galaxy S6 and S7 models. In the mid-range, devices like Playstation VR, Oculus Rift, HTC Vive for VR and Lenovo Phab 2 PRO, Epson Moverio etc. for AR offer reasonable experience (provided other hardware is already present for PSVR, Rift, and Vive to run on) in the 400 - 1,000\euro price range. Further down the line, now discontinued Google Glass explorer edition originally retailed for \$1,500, Microsoft HoloLens developer preview version is available for 3,000\$. Specialized filmmaking motion tracking environments and CAVE systems can cost up to hundreds of thousands euros while offering flawless precision.

It is important to consider additional costs of a system when examining the total price - powerful smartphones are needed for cardboard-type headsets, Vive and Rift require VR-ready computers, Playstation VR needs the PS4 console etc.
\item[Performance]a combination of the computational power and the quality of virtual object rendition. A more powerful device is generally able to display more complex sceneries at a lower delay and higher refresh rate and precision. Generally, the final screen gets rendered as a compromise between scene quality and rendering speed and high-complexity calculations should be avoided to leave out enough capacity for position detection arithmetics. Microsoft Hololens even employs a specifically designed hardware chip, called holographic processing unit (HPU), that solves this problem by performing position detection calculations.

There is generally a noticeable performance gap between mobile-device based AR/VR systems and those that employ dedicated computers.
\end{definitions}

\nocite{*}
\printbibliography

\end{document}